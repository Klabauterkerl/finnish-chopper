{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/Klabauterkerl/finnish-chopper/blob/main/fairseq_morfessor.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sacrebleu sentencepiece\n",
    "%pip install tensorboardX\n",
    "%pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "%pip install fairseq==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define paths for the mounted Google Drive\n",
    "base_path = \"/content/drive/MyDrive/translation_model\"\n",
    "dataset_path = f\"{base_path}/dataset\"\n",
    "!mkdir -p \"{dataset_path}\"\n",
    "data_bin_path = f\"{base_path}/data-bin\"\n",
    "checkpoints_path = f\"{base_path}/checkpoints\"\n",
    "logs_path = f\"{base_path}/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "!wget -P \"{dataset_path}\" https://www.statmt.org/europarl/v9/training/europarl-v9.fi-en.tsv.gz\n",
    "!gunzip \"{dataset_path}/europarl-v9.fi-en.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into two files, each containing one column of the original dataset\n",
    "!cut -f1 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/europarl-v9.fi\n",
    "!cut -f2 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/europarl-v9.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Moses for preprocessing\n",
    "!git clone https://github.com/moses-smt/mosesdecoder.git\n",
    "\n",
    "# Normalize punctuation and tokenize Finnish text\n",
    "!cat ${dataset_path}/europarl-v9.fi | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl fi | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -a -l fi \\\n",
    "> ${dataset_path}/europarl-v9.tok.fi\n",
    "\n",
    "# Normalize punctuation and tokenize English text\n",
    "!cat ${dataset_path}/europarl-v9.en | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl en | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -a -l en \\\n",
    "> ${dataset_path}/europarl-v9.tok.en\n",
    "\n",
    "# Train truecaser model for Finnish\n",
    "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
    "-corpus ${dataset_path}/europarl-v9.tok.fi \\\n",
    "-model ${dataset_path}/truecase-model.fi\n",
    "\n",
    "# Train truecaser model for English\n",
    "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
    "-corpus ${dataset_path}/europarl-v9.tok.en \\\n",
    "-model ${dataset_path}/truecase-model.en\n",
    "\n",
    "# Truecase the tokenized Finnish text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model ${dataset_path}/truecase-model.fi \\\n",
    "< ${dataset_path}/europarl-v9.tok.fi \\\n",
    "> ${dataset_path}/europarl-v9.tok.truecase.fi\n",
    "\n",
    "# Truecase the tokenized English text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model ${dataset_path}/truecase-model.en \\\n",
    "< ${dataset_path}/europarl-v9.tok.en \\\n",
    "> ${dataset_path}/europarl-v9.tok.truecase.en\n",
    "\n",
    "# Clean the corpus\n",
    "!perl mosesdecoder/scripts/training/clean-corpus-n.perl \\\n",
    "${dataset_path}/tokenized.tok.truecase en fi \\\n",
    "${dataset_path}/tokenized.tok.clean 1 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Morfessor for Morfessor-Encoding\n",
    "%pip install morfessor\n",
    "\n",
    "# Create Morfessor directory and set its path\n",
    "morfessor_path = f\"{dataset_path}/morfessor\"\n",
    "!mkdir -p \"{morfessor_path}\"\n",
    "\n",
    "# Learn Morfessor model from tokenized data\n",
    "!morfessor -t {dataset_path}/tokenized.tok.clean.fi -s {morfessor_path}/model_fi.bin\n",
    "!morfessor -t {dataset_path}/tokenized.tok.clean.en -s {morfessor_path}/model_en.bin\n",
    "# Segment Finnish tokenized data using learned Morfessor model\n",
    "!morfessor -l /content/drive/MyDrive/translation_model/dataset/morfessor/model_fi.bin -T - \\\n",
    "    --output-newlines --output-format \"{analysis}  \" --output-format-separator \" --\" \\\n",
    "    < /content/drive/MyDrive/translation_model/dataset/tokenized.tok.clean.fi > \\\n",
    "    /content/drive/MyDrive/translation_model/dataset/morfessor/europarl-v9.morfessor.fi\n",
    "!morfessor -l /content/drive/MyDrive/translation_model/dataset/morfessor/model_en.bin -T - \\\n",
    "    --output-newlines --output-format \"{analysis}  \" --output-format-separator \" --\" \\\n",
    "    < /content/drive/MyDrive/translation_model/dataset/tokenized.tok.clean.en > \\\n",
    "    /content/drive/MyDrive/translation_model/dataset/morfessor/europarl-v9.morfessor.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10000 {morfessor_path}/europarl-v9.morfessor.fi > {morfessor_path}/test.morfessor.fi\n",
    "!tail -n +10001 {morfessor_path}/europarl-v9.morfessor.fi | head -n 10000 > {morfessor_path}/valid.morfessor.fi\n",
    "!tail -n +20001 {morfessor_path}/europarl-v9.morfessor.fi > {morfessor_path}/train.morfessor.fi\n",
    "\n",
    "!head -n 10000 {morfessor_path}/europarl-v9.morfessor.en > {morfessor_path}/test.morfessor.en\n",
    "!tail -n +10001 {morfessor_path}/europarl-v9.morfessor.en | head -n 10000 > {morfessor_path}/valid.morfessor.en\n",
    "!tail -n +20001 {morfessor_path}/europarl-v9.morfessor.en > {morfessor_path}/train.morfessor.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the mounted Google Drive\n",
    "base_path = \"/content/drive/MyDrive/translation_model\"\n",
    "data_bin_path = f\"{base_path}/data-bin\"\n",
    "checkpoints_path = f\"{base_path}/checkpoints\"\n",
    "dataset_path = f\"{base_path}/dataset\"\n",
    "\n",
    "# Create directories in Google Drive\n",
    "!mkdir -p \"{data_bin_path}\"\n",
    "!mkdir -p \"{checkpoints_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset using Morfessor Data\n",
    "!fairseq-preprocess --source-lang fi --target-lang en \\\n",
    "    --trainpref {morfessor_path}/train.morfessor --validpref {morfessor_path}/valid.morfessor --testpref {dataset_path}/test.morfessor \\\n",
    "    --destdir {data_bin_path}/morfessor --joined-dictionary --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model using Morfessor Dataset\n",
    "!fairseq-train {data_bin_path}/morfessor \\\n",
    "    --arch transformer --share-all-embeddings \\\n",
    "    --encoder-layers 5 --decoder-layers 5 \\\n",
    "    --encoder-embed-dim 512 --decoder-embed-dim 512 \\\n",
    "    --encoder-ffn-embed-dim 2048 --decoder-ffn-embed-dim 2048 \\\n",
    "    --encoder-attention-heads 8 --decoder-attention-heads 8 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 \\\n",
    "    --optimizer adam --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
    "    --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
    "    --stop-min-lr 1e-09 --clip-norm 0.0 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --weight-decay 0.0001 --max-tokens 4096 \\\n",
    "    --update-freq 1 --max-epoch 30 --save-interval 1 \\\n",
    "    --keep-last-epochs 5 --log-format simple --log-interval 100 \\\n",
    "    --tensorboard-logdir {logs_path} --seed 42 \\\n",
    "    --save-dir {checkpoints_path}/morfessor \\\n",
    "    --amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate translations using Morfessor trained model\n",
    "! fairseq-generate {data_bin_path}/morfessor \\\n",
    "    --path {checkpoints_path}/morfessor/checkpoint_best.pt \\\n",
    "    --beam 5 --lenpen 1.2 \\\n",
    "    --gen-subset test \\\n",
    "    --remove-bpe > {base_path}/translations_morfessor.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU score\n",
    "!grep ^H {base_path}/translations.txt | cut -f3- > {base_path}/hyp.txt\n",
    "!grep ^T {base_path}/translations.txt | cut -f2- > {base_path}/ref.txt\n",
    "!mosesdecoder/scripts/generic/multi-bleu.perl {base_path}/ref.txt < {base_path}/hyp.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finnish-chopper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
