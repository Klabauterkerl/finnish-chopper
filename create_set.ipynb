{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths when locally running\n",
    "base_path = \"data/base\"\n",
    "dataset_path = f\"{base_path}/dataset\"\n",
    "data_bin_path = f\"{base_path}/data-bin\"\n",
    "checkpoints_path = f\"{base_path}/checkpoints\"\n",
    "logs_path = f\"{base_path}/logs\"\n",
    "evaluation_folder = f\"{base_path}/evaluation\"\n",
    "\n",
    "!mkdir -p \"{dataset_path}\"\n",
    "!mkdir -p \"{data_bin_path}\"\n",
    "!mkdir -p \"{checkpoints_path}\"\n",
    "!mkdir -p \"{logs_path}\"\n",
    "!mkdir -p \"{evaluation_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer Version 1.1\n",
      "Language: fi\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "clean-corpus.perl: processing data/base/dataset/test2.tok.truecase.en & .fi to data/base/dataset/test2.tok.clean, cutoff 1-50, ratio 9\n",
      "\n",
      "Input sentences: 3002  Output sentences:  2970\n"
     ]
    }
   ],
   "source": [
    "set_name = \"test2\"\n",
    "\n",
    "# Normalize punctuation and tokenize Finnish text\n",
    "!cat {dataset_path}/{set_name}.fi | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl fi | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l fi \\\n",
    "> {dataset_path}/{set_name}.tok.fi\n",
    "\n",
    "# Normalize punctuation and tokenize English text\n",
    "!cat {dataset_path}/{set_name}.en | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl en | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l en \\\n",
    "> {dataset_path}/{set_name}.tok.en\n",
    "\n",
    "# Truecase the tokenized Finnish text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model {dataset_path}/truecase-model.fi \\\n",
    "< {dataset_path}/{set_name}.tok.fi \\\n",
    "> {dataset_path}/{set_name}.tok.truecase.fi\n",
    "\n",
    "# Truecase the tokenized English text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model {dataset_path}/truecase-model.en \\\n",
    "< {dataset_path}/{set_name}.tok.en \\\n",
    "> {dataset_path}/{set_name}.tok.truecase.en\n",
    "\n",
    "# Clean the corpus\n",
    "!perl mosesdecoder/scripts/training/clean-corpus-n.perl \\\n",
    "{dataset_path}/{set_name}.tok.truecase en fi \\\n",
    "{dataset_path}/{set_name}.tok.clean 1 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = \"test2\"\n",
    "\n",
    "# Apply the learned BPE model and vocabulary to the dev & test set\n",
    "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
    "    --vocabulary {dataset_path}/vocab.fi < {dataset_path}/{set_name}.tok.clean.fi > {dataset_path}/{set_name}.bpe.fi\n",
    "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
    "    --vocabulary {dataset_path}/vocab.en < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-28 09:42:06 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='fi', target_lang='en', trainpref=None, validpref=None, testpref='data/base/dataset/test2.tok.clean', align_suffix=None, destdir='data/base/data-bin', thresholdtgt=0, thresholdsrc=0, tgtdict='data/bpe/data-bin/dict.en.txt', srcdict='data/bpe/data-bin/dict.fi.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=20, dict_only=False)\n",
      "2023-06-28 09:42:06 | INFO | fairseq_cli.preprocess | [fi] Dictionary: 26368 types\n",
      "2023-06-28 09:42:10 | INFO | fairseq_cli.preprocess | [fi] data/base/dataset/test2.tok.clean.fi: 2970 sents, 46613 tokens, 34.8% replaced (by <unk>)\n",
      "2023-06-28 09:42:10 | INFO | fairseq_cli.preprocess | [en] Dictionary: 14872 types\n",
      "2023-06-28 09:42:13 | INFO | fairseq_cli.preprocess | [en] data/base/dataset/test2.tok.clean.en: 2970 sents, 63594 tokens, 14.9% replaced (by <unk>)\n",
      "2023-06-28 09:42:13 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/base/data-bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang fi --target-lang en\\\n",
    "    --srcdict data/bpe/data-bin/dict.fi.txt \\\n",
    "    --tgtdict data/bpe/data-bin/dict.en.txt \\\n",
    "    --testpref {dataset_path}/test2.tok.clean \\\n",
    "    --destdir {data_bin_path} \\\n",
    "    --workers 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-generate {data_bin_path} \\\n",
    "    --path {checkpoints_path}/checkpoint_best.pt \\\n",
    "    --batch-size 128 --beam 5 --remove-bpe \\\n",
    "    --scoring sacrebleu --sacrebleu\\\n",
    "    > {base_path}/translations_sacrebleu.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finnish-chopper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
