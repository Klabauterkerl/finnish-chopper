{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths when locally running\n",
    "base_path = \"data/base\"\n",
    "dataset_path = f\"{base_path}/dataset\"\n",
    "data_bin_path = f\"{base_path}/data-bin\"\n",
    "checkpoints_path = f\"{base_path}/checkpoints\"\n",
    "logs_path = f\"{base_path}/logs\"\n",
    "evaluation_folder = f\"{base_path}/evaluation\"\n",
    "\n",
    "!mkdir -p \"{dataset_path}\"\n",
    "!mkdir -p \"{data_bin_path}\"\n",
    "!mkdir -p \"{checkpoints_path}\"\n",
    "!mkdir -p \"{logs_path}\"\n",
    "!mkdir -p \"{evaluation_folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train truecaser model for Finnish\n",
    "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
    "-corpus {dataset_path}/train.fi \\\n",
    "-model {dataset_path}/truecase-model.fi\n",
    "\n",
    "# Train truecaser model for English\n",
    "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
    "-corpus {dataset_path}/train.en \\\n",
    "-model {dataset_path}/truecase-model.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = \"test2\"\n",
    "\n",
    "# Normalize punctuation and tokenize Finnish text\n",
    "!cat {dataset_path}/{set_name}.fi | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl fi | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l fi \\\n",
    "> {dataset_path}/{set_name}.tok.fi\n",
    "\n",
    "# Normalize punctuation and tokenize English text\n",
    "!cat {dataset_path}/{set_name}.en | \\\n",
    "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl en | \\\n",
    "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l en \\\n",
    "> {dataset_path}/{set_name}.tok.en\n",
    "\n",
    "# Truecase the tokenized Finnish text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model {dataset_path}/truecase-model.fi \\\n",
    "< {dataset_path}/{set_name}.tok.fi \\\n",
    "> {dataset_path}/{set_name}.tok.truecase.fi\n",
    "\n",
    "# Truecase the tokenized English text\n",
    "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
    "-model {dataset_path}/truecase-model.en \\\n",
    "< {dataset_path}/{set_name}.tok.en \\\n",
    "> {dataset_path}/{set_name}.tok.truecase.en\n",
    "\n",
    "# Clean the corpus\n",
    "!perl mosesdecoder/scripts/training/clean-corpus-n.perl \\\n",
    "{dataset_path}/{set_name}.tok.truecase en fi \\\n",
    "{dataset_path}/{set_name}.tok.clean 1 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = \"test2\"\n",
    "bpe_path = \"data/bpe/dataset\"\n",
    "\n",
    "# Apply the learned BPE model and vocabulary to the dev & test set\n",
    "!subword-nmt apply-bpe -c {bpe_path}/bpe.codes \\\n",
    "    --vocabulary {bpe_path}/vocab.fi < {dataset_path}/{set_name}.tok.clean.fi > {dataset_path}/{set_name}.bpe.fi\n",
    "!subword-nmt apply-bpe -c {bpe_path}/bpe.codes \\\n",
    "    --vocabulary {bpe_path}/vocab.en < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-preprocess --source-lang fi --target-lang en\\\n",
    "    --srcdict data/bpe/data-bin/dict.fi.txt \\\n",
    "    --tgtdict data/bpe/data-bin/dict.en.txt \\\n",
    "    --testpref {dataset_path}/test2.tok.clean \\\n",
    "    --destdir {data_bin_path} \\\n",
    "    --workers 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=4,5,6,7 fairseq-generate {data_bin_path} \\\n",
    "    --path data/bpe/checkpoints/checkpoint_best.pt \\\n",
    "    --batch-size 128 --beam 5 --remove-bpe \\\n",
    "    --scoring sacrebleu --sacrebleu\\\n",
    "    > {base_path}/translations_sacrebleu.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'{base_path}/translations_sacrebleu.txt'  # File generated by fairseq-generate\n",
    "reordered_output_file = f'{base_path}/reordered_output.txt'  # File to save the reordered translations\n",
    "\n",
    "# Read the output file and extract translations\n",
    "with open(output_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "translations = {}\n",
    "for line in lines:\n",
    "    if line.startswith('H-'):\n",
    "        parts = line.split('\\t')\n",
    "        index = int(parts[0].split('-')[1])\n",
    "        translation = parts[2].strip()\n",
    "        translations[index] = translation\n",
    "\n",
    "# Reorder translations and save to file\n",
    "with open(reordered_output_file, 'w') as f:\n",
    "    for i in sorted(translations.keys()):\n",
    "        f.write(translations[i] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_folder = \"data/base/evaluation\"\n",
    "!mkdir -p \"{evaluation_folder}\"\n",
    "set_name = \"test2\"\n",
    "\n",
    "# Reverse the truecasing of the reference test2 set (English)\n",
    "!mosesdecoder/scripts/recaser/detruecase.perl \\\n",
    "< {dataset_path}/test2.tok.clean.en \\\n",
    "> {evaluation_folder}/test2.tok.en\n",
    "\n",
    "# Reverse the truecasing of the source test2 set (Finnish)\n",
    "!mosesdecoder/scripts/recaser/detruecase.perl \\\n",
    "< {dataset_path}/test2.tok.clean.fi \\\n",
    "> {evaluation_folder}/test2.tok.fi\n",
    "\n",
    "# Reverse the tokenization of the reference test2 set (English)\n",
    "!mosesdecoder/scripts/tokenizer/detokenizer.perl -l en \\\n",
    "< {evaluation_folder}/test2.tok.en \\\n",
    "> {evaluation_folder}/test2.detok.en\n",
    "\n",
    "# Reverse the tokenization of the source test2 set (Finnish)\n",
    "!mosesdecoder/scripts/tokenizer/detokenizer.perl -l fi \\\n",
    "< {evaluation_folder}/test2.tok.fi \\\n",
    "> {evaluation_folder}/test2.detok.fi\n",
    "\n",
    "# Reverse the punctuation normalization of the reference test2 set (English)\n",
    "!mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -r \\\n",
    "< {evaluation_folder}/test2.detok.en \\\n",
    "> {evaluation_folder}/test2.en\n",
    "\n",
    "# Reverse the punctuation normalization of the source test2 set (Finnish)\n",
    "!mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -r \\\n",
    "< {evaluation_folder}/test2.detok.fi \\\n",
    "> {evaluation_folder}/test2.fi\n",
    "\n",
    "# Reverse the truecasing of the hypothesis translations (English)\n",
    "!mosesdecoder/scripts/recaser/detruecase.perl \\\n",
    "< {base_path}/reordered_output.txt \\\n",
    "> {evaluation_folder}/reordered_output.truecase.txt\n",
    "\n",
    "# Reverse the tokenization of the hypothesis translations (English)\n",
    "!mosesdecoder/scripts/tokenizer/detokenizer.perl -l en \\\n",
    "< {evaluation_folder}/reordered_output.truecase.txt \\\n",
    "> {evaluation_folder}/reordered_output.detok.txt\n",
    "\n",
    "# Reverse the punctuation normalization of the hypothesis translations (English)\n",
    "!mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -r \\\n",
    "< {evaluation_folder}/reordered_output.detok.txt \\\n",
    "> {evaluation_folder}/reordered_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacrebleu {evaluation_folder}/test2.en < {evaluation_folder}/reordered_output.txt > {evaluation_folder}/sacrebleu_score.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=4,5,6,7 comet-score -t {evaluation_folder}/reordered_output.txt -r {evaluation_folder}/test2.en -s {evaluation_folder}/test2.fi > {evaluation_folder}/comet_score.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finnish-chopper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
