{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/Klabauterkerl/finnish-chopper/blob/main/fairseq_bpe.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k32IU6kfnbn"
      },
      "outputs": [],
      "source": [
        "# Install fairseq and other dependencies\n",
        "%pip install fairseq\n",
        "%pip install sacrebleu sentencepiece\n",
        "%pip install tensorboardX\n",
        "%pip install subword-nmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hehwT42_4HzH",
        "outputId": "5214d06b-3752-4db4-ad05-08cf2590c35c"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for the mounted Google Drive\n",
        "base_path = \"/content/drive/MyDrive/translation_model\"\n",
        "dataset_path = f\"{base_path}/dataset\"\n",
        "data_bin_path = f\"{base_path}/data-bin\"\n",
        "checkpoints_path = f\"{base_path}/checkpoints\"\n",
        "logs_path = f\"{base_path}/logs\"\n",
        "\n",
        "# Create directories in Google Drive\n",
        "!mkdir -p \"{dataset_path}\"\n",
        "!mkdir -p \"{data_bin_path}\"\n",
        "!mkdir -p \"{checkpoints_path}\"\n",
        "!mkdir -p \"{logs_path}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths when locally running\n",
        "base_path = \"data\"\n",
        "dataset_path = f\"{base_path}/dataset\"\n",
        "data_bin_path = f\"{base_path}/data-bin\"\n",
        "checkpoints_path = f\"{base_path}/checkpoints\"\n",
        "logs_path = f\"{base_path}/logs\"\n",
        "\n",
        "!mkdir -p \"{dataset_path}\"\n",
        "!mkdir -p \"{data_bin_path}\"\n",
        "!mkdir -p \"{checkpoints_path}\"\n",
        "!mkdir -p \"{logs_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEbPx3wLfyDt"
      },
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "!wget -P \"{dataset_path}\" https://www.statmt.org/europarl/v9/training/europarl-v9.fi-en.tsv.gz\n",
        "!gunzip \"{dataset_path}/europarl-v9.fi-en.tsv.gz\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cReXcKyN02ti"
      },
      "outputs": [],
      "source": [
        "# Split dataset into two files, each containing one column of the original dataset\n",
        "\n",
        "!cut -f1 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/train.fi\n",
        "!cut -f2 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/train.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Moses for preprocessing\n",
        "!git clone https://github.com/moses-smt/mosesdecoder.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knhTxHFS14GV"
      },
      "outputs": [],
      "source": [
        "# Train truecaser model for Finnish\n",
        "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
        "-corpus {dataset_path}/train.fi \\\n",
        "-model {dataset_path}/truecase-model.fi\n",
        "\n",
        "# Train truecaser model for English\n",
        "!mosesdecoder/scripts/recaser/train-truecaser.perl \\\n",
        "-corpus {dataset_path}/train.en \\\n",
        "-model {dataset_path}/truecase-model.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_name = \"train\"\n",
        "\n",
        "# Normalize punctuation and tokenize Finnish text\n",
        "!cat {dataset_path}/{set_name}.fi | \\\n",
        "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl fi | \\\n",
        "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l fi \\\n",
        "> {dataset_path}/{set_name}.tok.fi\n",
        "\n",
        "# Normalize punctuation and tokenize English text\n",
        "!cat {dataset_path}/{set_name}.en | \\\n",
        "mosesdecoder/scripts/tokenizer/normalize-punctuation.perl en | \\\n",
        "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -no-escape -l en \\\n",
        "> {dataset_path}/{set_name}.tok.en\n",
        "\n",
        "# Truecase the tokenized Finnish text\n",
        "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
        "-model {dataset_path}/truecase-model.fi \\\n",
        "< {dataset_path}/{set_name}.tok.fi \\\n",
        "> {dataset_path}/{set_name}.tok.truecase.fi\n",
        "\n",
        "# Truecase the tokenized English text\n",
        "!mosesdecoder/scripts/recaser/truecase.perl \\\n",
        "-model {dataset_path}/truecase-model.en \\\n",
        "< {dataset_path}/{set_name}.tok.en \\\n",
        "> {dataset_path}/{set_name}.tok.truecase.en\n",
        "\n",
        "# Clean the corpus\n",
        "!perl mosesdecoder/scripts/training/clean-corpus-n.perl \\\n",
        "{dataset_path}/{set_name}.tok.truecase en fi \\\n",
        "{dataset_path}/{set_name}.tok.clean 1 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihQMl1vmu9OX"
      },
      "outputs": [],
      "source": [
        "set_name = \"train\"\n",
        "\n",
        "# Learn a joint BPE model and vocabulary\n",
        "!subword-nmt learn-joint-bpe-and-vocab \\\n",
        "     --input {dataset_path}/{set_name}.tok.clean.fi {dataset_path}/{set_name}.tok.clean.en -s 32000 \\\n",
        "     -o {dataset_path}/bpe.codes --write-vocabulary {dataset_path}/vocab.fi {dataset_path}/vocab.en\n",
        "\n",
        "# Apply the learned BPE model and vocabulary\n",
        "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
        "     --vocabulary {dataset_path}/vocab.fi < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.fi\n",
        "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
        "     --vocabulary {dataset_path}/vocab.en < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_name = \"train\"\n",
        "\n",
        "# Apply the learned BPE model and vocabulary to the dev & test set\n",
        "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
        "    --vocabulary {dataset_path}/vocab.fi < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.fi\n",
        "!subword-nmt apply-bpe -c {dataset_path}/bpe.codes \\\n",
        "    --vocabulary {dataset_path}/vocab.en < {dataset_path}/{set_name}.tok.clean.en > {dataset_path}/{set_name}.bpe.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlE7ZVXugBpM"
      },
      "outputs": [],
      "source": [
        "# Define paths for the mounted Google Drive\n",
        "base_path = \"/content/drive/MyDrive/translation_model\"\n",
        "data_bin_path = f\"{base_path}/data-bin\"\n",
        "checkpoints_path = f\"{base_path}/checkpoints\"\n",
        "dataset_path = f\"{base_path}/dataset\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJUK2lKjVvay"
      },
      "outputs": [],
      "source": [
        "# Create Dataset using BPE Data\n",
        "!fairseq-preprocess --source-lang fi --target-lang en \\\n",
        "    --trainpref {bpe_path}/train.bpe --validpref {bpe_path}/valid.bpe --testpref {bpe_path}/test.bpe \\\n",
        "    --destdir {data_bin_path}/bpe --joined-dictionary --workers 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1yS_2poZdHp"
      },
      "outputs": [],
      "source": [
        "# Train Model using BPE Dataset\n",
        "!fairseq-train \"{data_bin_path}/bpe\" \\\n",
        "    --arch transformer --share-all-embeddings \\\n",
        "    --encoder-layers 5 --decoder-layers 5 \\\n",
        "    --encoder-embed-dim 512 --decoder-embed-dim 512 \\\n",
        "    --encoder-ffn-embed-dim 2048 --decoder-ffn-embed-dim 2048 \\\n",
        "    --encoder-attention-heads 8 --decoder-attention-heads 8 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 \\\n",
        "    --optimizer adam --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "    --stop-min-lr 1e-09 --clip-norm 0.0 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --weight-decay 0.0001 --max-tokens 4096 \\\n",
        "    --update-freq 1 --max-epoch 30 --save-interval 1 \\\n",
        "    --keep-last-epochs 5 --log-format simple --log-interval 100 \\\n",
        "    --tensorboard-logdir \"{logs_path} --seed 42\" \\\n",
        "    --save-dir \"{checkpoints_path}/bpe\" \\\n",
        "    --amp --patience 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8UjyFVVnDXA"
      },
      "outputs": [],
      "source": [
        "# Generate translations using BPE trained model\n",
        "! fairseq-generate \"{data_bin_path}/bpe\" \\\n",
        "    --path \"{checkpoints_path}/bpe/checkpoint_best.pt\" \\\n",
        "    --beam 5 --lenpen 1.2 \\\n",
        "    --quiet \\\n",
        "    --gen-subset test \\\n",
        "    --remove-bpe > \"{base_path}/translations_bpe.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjh2Zer4heK4"
      },
      "outputs": [],
      "source": [
        "# Compute BLEU score\n",
        "!cat \"{base_path}/translations_bpe.txt\" | sacrebleu {dataset_path}/test.en"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
