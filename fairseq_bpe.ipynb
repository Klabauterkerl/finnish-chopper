{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/Klabauterkerl/finnish-chopper/blob/main/fairseq_bpe.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k32IU6kfnbn"
      },
      "outputs": [],
      "source": [
        "%pip install fairseq\n",
        "%pip install sacrebleu sentencepiece\n",
        "%pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hehwT42_4HzH",
        "outputId": "5214d06b-3752-4db4-ad05-08cf2590c35c"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for the mounted Google Drive\n",
        "base_path = \"/content/drive/MyDrive/translation_model\"\n",
        "dataset_path = f\"{base_path}/dataset\"\n",
        "!mkdir -p \"{dataset_path}\"\n",
        "data_bin_path = f\"{base_path}/data-bin\"\n",
        "checkpoints_path = f\"{base_path}/checkpoints\"\n",
        "logs_path = f\"{base_path}/logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEbPx3wLfyDt"
      },
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "!wget -P \"{dataset_path}\" https://www.statmt.org/europarl/v9/training/europarl-v9.fi-en.tsv.gz\n",
        "!gunzip \"{dataset_path}/europarl-v9.fi-en.tsv.gz\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cReXcKyN02ti"
      },
      "outputs": [],
      "source": [
        "# Split dataset into two files, each containing one column of the original dataset\n",
        "!cut -f1 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/europarl-v9.fi\n",
        "!cut -f2 {dataset_path}/europarl-v9.fi-en.tsv > {dataset_path}/europarl-v9.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knhTxHFS14GV"
      },
      "outputs": [],
      "source": [
        "# Install Moses for preprocessing\n",
        "!git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "\n",
        "# Normalize & Tokenize Finnish and English texts\n",
        "!cat {dataset_path}/europarl-v9.fi | mosesdecoder/scripts/tokenizer/normalize-punctuation.perl fi |\\\n",
        "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -a -l fi\\\n",
        "> {dataset_path}/europarl-v9.tok.fi\n",
        "!cat {dataset_path}/europarl-v9.en | mosesdecoder/scripts/tokenizer/normalize-punctuation.perl en |\\\n",
        "mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -a -l en \\\n",
        "> {dataset_path}/europarl-v9.tok.en\n",
        "\n",
        "!perl mosesdecoder/scripts/training/clean-corpus-n.perl {dataset_path}/europarl-v9.tok fi en \\\n",
        "    {dataset_path}/tokenized.tok.clean 1 50 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihQMl1vmu9OX"
      },
      "outputs": [],
      "source": [
        "# Install subword-nmt for BPE-encoding\n",
        "%pip install subword-nmt\n",
        "\n",
        "# Create BPE directory and set its path\n",
        "bpe_path = f\"{dataset_path}/bpe\"\n",
        "!mkdir -p \"{bpe_path}\"\n",
        "\n",
        "# Learn a joint BPE model and vocabulary\n",
        "!subword-nmt learn-joint-bpe-and-vocab \\\n",
        "     --input {dataset_path}/tokenized.tok.clean.fi {dataset_path}/tokenized.tok.clean.en -s 32000 \\\n",
        "     -o {dataset_path}/bpe.codes --write-vocabulary {dataset_path}/vocab.fi {dataset_path}/vocab.en\n",
        "# Apply the learned BPE model and vocabulary\n",
        "!subword-nmt apply-bpe -c {bpe_path}/bpe.codes \\\n",
        "     --vocabulary {bpe_path}/vocab.fi < {bpe_path}/europarl-v9.fi.tok > {bpe_path}/europarl-v9.bpe.fi\n",
        "!subword-nmt apply-bpe -c {bpe_path}/bpe.codes \\\n",
        "     --vocabulary {bpe_path}/vocab.en < {bpe_path}/europarl-v9.en.tok > {bpe_path}/europarl-v9.bpe.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOjNBA734ZPy"
      },
      "outputs": [],
      "source": [
        "!head -n 10000 {bpe_path}/europarl-v9.bpe.fi > {bpe_path}/test.bpe.fi\n",
        "!tail -n +10001 {bpe_path}/europarl-v9.bpe.fi | head -n 10000 > {bpe_path}/valid.bpe.fi\n",
        "!tail -n +20001 {bpe_path}/europarl-v9.bpe.fi > {bpe_path}/train.bpe.fi\n",
        "\n",
        "!head -n 10000 {bpe_path}/europarl-v9.bpe.en > {bpe_path}/test.bpe.en\n",
        "!tail -n +10001 {bpe_path}/europarl-v9.bpe.en | head -n 10000 > {bpe_path}/valid.bpe.en\n",
        "!tail -n +20001 {bpe_path}/europarl-v9.bpe.en > {bpe_path}/train.bpe.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlE7ZVXugBpM"
      },
      "outputs": [],
      "source": [
        "# Define paths for the mounted Google Drive\n",
        "base_path = \"/content/drive/MyDrive/translation_model\"\n",
        "data_bin_path = f\"{base_path}/data-bin\"\n",
        "checkpoints_path = f\"{base_path}/checkpoints\"\n",
        "dataset_path = f\"{base_path}/dataset\"\n",
        "\n",
        "# Create directories in Google Drive\n",
        "!mkdir -p \"{data_bin_path}\"\n",
        "!mkdir -p \"{checkpoints_path}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJUK2lKjVvay"
      },
      "outputs": [],
      "source": [
        "# Create Dataset using BPE Data\n",
        "!fairseq-preprocess --source-lang fi --target-lang en \\\n",
        "    --trainpref {dataset_path}/train.bpe --validpref {dataset_path}/valid.bpe --testpref {dataset_path}/test.bpe \\\n",
        "    --destdir {data_bin_path}/bpe --joined-dictionary --workers 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1yS_2poZdHp"
      },
      "outputs": [],
      "source": [
        "# Train Model using BPE Dataset\n",
        "!fairseq-train {data_bin_path}/bpe \\\n",
        "    --arch transformer --share-all-embeddings \\\n",
        "    --encoder-layers 5 --decoder-layers 5 \\\n",
        "    --encoder-embed-dim 512 --decoder-embed-dim 512 \\\n",
        "    --encoder-ffn-embed-dim 2048 --decoder-ffn-embed-dim 2048 \\\n",
        "    --encoder-attention-heads 8 --decoder-attention-heads 8 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 \\\n",
        "    --optimizer adam --lr 0.0005 --lr-scheduler inverse_sqrt \\\n",
        "    --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "    --stop-min-lr 1e-09 --clip-norm 0.0 \\\n",
        "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "    --weight-decay 0.0001 --max-tokens 4096 \\\n",
        "    --update-freq 1 --max-epoch 30 --save-interval 1 \\\n",
        "    --keep-last-epochs 5 --log-format simple --log-interval 100 \\\n",
        "    --tensorboard-logdir {logs_path} --seed 42 \\\n",
        "    --save-dir {checkpoints_path}/bpe \\\n",
        "    --amp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8UjyFVVnDXA"
      },
      "outputs": [],
      "source": [
        "# Generate translations using BPE trained model\n",
        "! fairseq-generate {data_bin_path}/bpe \\\n",
        "    --path {checkpoints_path}/bpe/checkpoint_best.pt \\\n",
        "    --beam 5 --lenpen 1.2 \\\n",
        "    --gen-subset test \\\n",
        "    --remove-bpe > {base_path}/translations_bpe.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjh2Zer4heK4"
      },
      "outputs": [],
      "source": [
        "# Compute BLEU score\n",
        "!grep ^H {base_path}/translations.txt | cut -f3- > {base_path}/hyp.txt\n",
        "!grep ^T {base_path}/translations.txt | cut -f2- > {base_path}/ref.txt\n",
        "!mosesdecoder/scripts/generic/multi-bleu.perl {base_path}/ref.txt < {base_path}/hyp.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
